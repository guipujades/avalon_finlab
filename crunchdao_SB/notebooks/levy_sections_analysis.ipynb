{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Quebras Estruturais com Seções de Lévy\n",
    "\n",
    "Este notebook demonstra como usar o método das seções de Lévy para:\n",
    "1. Detectar mudanças de regime de volatilidade em séries temporais\n",
    "2. Extrair features robustas para machine learning\n",
    "3. Comparar com o desempenho do TSFresh\n",
    "\n",
    "Baseado no artigo de Figueiredo et al. (2022) e na implementação para o projeto CrunchDAO SB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar nossa implementação\n",
    "from src.features.levy_sections import LevySectionsAnalyzer, analyze_structural_breaks_for_series\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para carregar dados\n",
    "def load_data(ticker, start_date, end_date):\n",
    "    \"\"\"Carrega dados do Yahoo Finance e calcula retornos\"\"\"\n",
    "    print(f\"Carregando {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "    data['Returns'] = np.log(data['Close'] / data['Close'].shift(1))\n",
    "    return data.dropna()\n",
    "\n",
    "# Carregar múltiplos ativos para comparação\n",
    "tickers = {\n",
    "    '^BVSP': 'IBOVESPA',\n",
    "    '^GSPC': 'S&P 500',\n",
    "    'BTC-USD': 'Bitcoin',\n",
    "    'PETR4.SA': 'Petrobras'\n",
    "}\n",
    "\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "data_dict = {}\n",
    "for ticker, name in tickers.items():\n",
    "    try:\n",
    "        data_dict[ticker] = load_data(ticker, start_date, end_date)\n",
    "        print(f\"✓ {name}: {len(data_dict[ticker])} observações\")\n",
    "    except:\n",
    "        print(f\"✗ Erro ao carregar {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória dos Retornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar retornos e volatilidade\n",
    "fig, axes = plt.subplots(len(data_dict), 2, figsize=(15, 3*len(data_dict)))\n",
    "\n",
    "for i, (ticker, data) in enumerate(data_dict.items()):\n",
    "    # Retornos\n",
    "    ax1 = axes[i, 0] if len(data_dict) > 1 else axes[0]\n",
    "    ax1.plot(data.index, data['Returns'], linewidth=0.5)\n",
    "    ax1.set_title(f'{tickers[ticker]} - Retornos Diários')\n",
    "    ax1.set_ylabel('Log-retorno')\n",
    "    \n",
    "    # Volatilidade realizada (janela de 20 dias)\n",
    "    ax2 = axes[i, 1] if len(data_dict) > 1 else axes[1]\n",
    "    vol = data['Returns'].rolling(20).std() * np.sqrt(252)\n",
    "    ax2.plot(data.index, vol)\n",
    "    ax2.set_title(f'{tickers[ticker]} - Volatilidade Anualizada (20d)')\n",
    "    ax2.set_ylabel('Volatilidade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estatísticas descritivas\n",
    "stats_df = pd.DataFrame()\n",
    "for ticker, data in data_dict.items():\n",
    "    stats = {\n",
    "        'Média': data['Returns'].mean() * 252,\n",
    "        'Volatilidade': data['Returns'].std() * np.sqrt(252),\n",
    "        'Sharpe': (data['Returns'].mean() * 252) / (data['Returns'].std() * np.sqrt(252)),\n",
    "        'Curtose': data['Returns'].kurtosis(),\n",
    "        'Assimetria': data['Returns'].skew(),\n",
    "        'VaR 5%': data['Returns'].quantile(0.05),\n",
    "        'CVaR 5%': data['Returns'][data['Returns'] <= data['Returns'].quantile(0.05)].mean()\n",
    "    }\n",
    "    stats_df[tickers[ticker]] = stats\n",
    "\n",
    "print(\"\\nEstatísticas dos Retornos:\")\n",
    "print(stats_df.round(4).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aplicação das Seções de Lévy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher ativo para análise detalhada\n",
    "selected_ticker = '^BVSP'\n",
    "data = data_dict[selected_ticker]\n",
    "returns = data['Returns'].values\n",
    "\n",
    "print(f\"Analisando {tickers[selected_ticker]}...\")\n",
    "print(f\"Período: {data.index[0].strftime('%Y-%m-%d')} a {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total de observações: {len(returns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar diferentes valores de tau\n",
    "tau_values = [0.001, 0.005, 0.01, 0.02, 0.05]\n",
    "results_by_tau = {}\n",
    "\n",
    "for tau in tau_values:\n",
    "    analyzer = LevySectionsAnalyzer(tau=tau, q=5)\n",
    "    levy_result = analyzer.compute_levy_sections(returns)\n",
    "    \n",
    "    results_by_tau[tau] = {\n",
    "        'analyzer': analyzer,\n",
    "        'result': levy_result,\n",
    "        'n_sections': len(levy_result.S_tau),\n",
    "        'mean_duration': np.mean(levy_result.durations),\n",
    "        'std_duration': np.std(levy_result.durations),\n",
    "        'cv_duration': np.std(levy_result.durations) / np.mean(levy_result.durations)\n",
    "    }\n",
    "\n",
    "# Resumo dos resultados\n",
    "summary_df = pd.DataFrame(results_by_tau).T\n",
    "summary_df = summary_df[['n_sections', 'mean_duration', 'std_duration', 'cv_duration']]\n",
    "print(\"\\nResumo para diferentes valores de tau:\")\n",
    "print(summary_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detecção de Quebras Estruturais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise detalhada com tau = 0.005\n",
    "tau_selected = 0.005\n",
    "analyzer = results_by_tau[tau_selected]['analyzer']\n",
    "levy_result = results_by_tau[tau_selected]['result']\n",
    "\n",
    "# Detectar quebras\n",
    "breaks_info = analyzer.detect_structural_breaks()\n",
    "\n",
    "print(f\"\\nAnálise com tau = {tau_selected}:\")\n",
    "print(f\"Quebras estruturais detectadas: {len(breaks_info['breaks'])}\")\n",
    "\n",
    "# Mapear quebras para datas\n",
    "for i, brk in enumerate(breaks_info['breaks']):\n",
    "    section_idx = brk['index']\n",
    "    if section_idx < len(levy_result.start_indices):\n",
    "        date_idx = levy_result.start_indices[section_idx]\n",
    "        if date_idx < len(data.index):\n",
    "            break_date = data.index[date_idx]\n",
    "            print(f\"\\nQuebra {i+1}:\")\n",
    "            print(f\"  Data: {break_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Mudança na duração média: {brk['mean_before']:.1f} → {brk['mean_after']:.1f} dias\")\n",
    "            print(f\"  Razão de mudança: {brk['change_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das quebras\n",
    "fig = analyzer.plot_analysis(breaks_info, title_prefix=tickers[selected_ticker])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparação com Eventos de Mercado Conhecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventos importantes no período\n",
    "market_events = [\n",
    "    ('2020-02-20', '2020-03-23', 'COVID-19 Crash', 'red'),\n",
    "    ('2021-01-27', '2021-02-05', 'GameStop/Reddit Rally', 'orange'),\n",
    "    ('2022-02-24', '2022-03-08', 'Invasão da Ucrânia', 'darkred'),\n",
    "    ('2023-03-10', '2023-03-20', 'Crise SVB/Credit Suisse', 'purple')\n",
    "]\n",
    "\n",
    "# Plotar série temporal com eventos e quebras detectadas\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), height_ratios=[2, 1])\n",
    "\n",
    "# Subplot 1: Preço e eventos\n",
    "ax1.plot(data.index, data['Close'], label='Preço de Fechamento', color='black', linewidth=1)\n",
    "\n",
    "# Adicionar eventos conhecidos\n",
    "for start, end, event, color in market_events:\n",
    "    start_date = pd.to_datetime(start)\n",
    "    end_date = pd.to_datetime(end)\n",
    "    if start_date >= data.index[0] and end_date <= data.index[-1]:\n",
    "        ax1.axvspan(start_date, end_date, alpha=0.3, color=color, label=event)\n",
    "\n",
    "# Adicionar quebras detectadas\n",
    "for brk in breaks_info['breaks']:\n",
    "    section_idx = brk['index']\n",
    "    if section_idx < len(levy_result.start_indices):\n",
    "        date_idx = levy_result.start_indices[section_idx]\n",
    "        if date_idx < len(data.index):\n",
    "            break_date = data.index[date_idx]\n",
    "            ax1.axvline(break_date, color='green', linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "ax1.set_title(f'{tickers[selected_ticker]} - Eventos de Mercado vs. Quebras Detectadas (Linhas Verdes)')\n",
    "ax1.set_ylabel('Preço')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Durações das seções\n",
    "section_dates = [data.index[idx] if idx < len(data.index) else data.index[-1] \n",
    "                 for idx in levy_result.start_indices]\n",
    "ax2.plot(section_dates[:len(levy_result.durations)], levy_result.durations, \n",
    "         'o-', markersize=4, label='Duração das Seções')\n",
    "ax2.set_ylabel('Duração (dias)')\n",
    "ax2.set_xlabel('Data')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extração de Features para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair features de todos os ativos\n",
    "features_all = {}\n",
    "\n",
    "for ticker in data_dict.keys():\n",
    "    returns = data_dict[ticker]['Returns'].values\n",
    "    \n",
    "    # Usar tau = 0.005 como padrão\n",
    "    analyzer = LevySectionsAnalyzer(tau=0.005, q=5)\n",
    "    analyzer.compute_levy_sections(returns)\n",
    "    features = analyzer.extract_features()\n",
    "    \n",
    "    features_all[tickers[ticker]] = features\n",
    "\n",
    "# Criar DataFrame com features\n",
    "features_df = pd.DataFrame(features_all).T\n",
    "\n",
    "# Selecionar features mais importantes\n",
    "important_features = [\n",
    "    'levy_duration_mean',\n",
    "    'levy_duration_cv',\n",
    "    'levy_duration_kurtosis',\n",
    "    'levy_norm_kurtosis',\n",
    "    'levy_shapiro_pvalue',\n",
    "    'levy_duration_autocorr'\n",
    "]\n",
    "\n",
    "print(\"\\nFeatures de Lévy para cada ativo:\")\n",
    "print(features_df[important_features].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlação entre features\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = features_df[important_features].T.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlação entre Ativos (Features de Lévy)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Robustez: Variação de Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de sensibilidade aos parâmetros\n",
    "q_values = [3, 5, 10, 15]\n",
    "tau = 0.005\n",
    "\n",
    "sensitivity_results = []\n",
    "\n",
    "for q in q_values:\n",
    "    analyzer = LevySectionsAnalyzer(tau=tau, q=q)\n",
    "    levy_result = analyzer.compute_levy_sections(returns)\n",
    "    breaks_info = analyzer.detect_structural_breaks()\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'q': q,\n",
    "        'n_sections': len(levy_result.S_tau),\n",
    "        'n_breaks': len(breaks_info['breaks']),\n",
    "        'mean_duration': np.mean(levy_result.durations),\n",
    "        'cv_duration': np.std(levy_result.durations) / np.mean(levy_result.durations)\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "print(\"\\nSensibilidade ao parâmetro q:\")\n",
    "print(sensitivity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Aplicação Prática: Sinal de Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular estratégia baseada em quebras estruturais\n",
    "# Ideia: Reduzir exposição quando detectada quebra para regime de alta volatilidade\n",
    "\n",
    "analyzer = LevySectionsAnalyzer(tau=0.005, q=5)\n",
    "levy_result = analyzer.compute_levy_sections(returns)\n",
    "breaks_info = analyzer.detect_structural_breaks()\n",
    "\n",
    "# Criar série de sinais\n",
    "signals = pd.Series(1, index=data.index)  # 1 = long, 0 = flat\n",
    "\n",
    "for brk in breaks_info['breaks']:\n",
    "    if brk['change_ratio'] < 0.7:  # Aumento de volatilidade\n",
    "        section_idx = brk['index']\n",
    "        if section_idx < len(levy_result.start_indices):\n",
    "            date_idx = levy_result.start_indices[section_idx]\n",
    "            if date_idx < len(data.index):\n",
    "                break_date = data.index[date_idx]\n",
    "                # Ficar flat por 20 dias após quebra\n",
    "                end_date = break_date + timedelta(days=20)\n",
    "                signals[break_date:end_date] = 0\n",
    "\n",
    "# Calcular retornos da estratégia\n",
    "strategy_returns = data['Returns'] * signals.shift(1)  # Shift para evitar look-ahead bias\n",
    "buy_hold_returns = data['Returns']\n",
    "\n",
    "# Performance cumulativa\n",
    "cumulative_strategy = (1 + strategy_returns).cumprod()\n",
    "cumulative_buyhold = (1 + buy_hold_returns).cumprod()\n",
    "\n",
    "# Plotar resultados\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(cumulative_buyhold.index, cumulative_buyhold.values, \n",
    "         label='Buy & Hold', linewidth=2)\n",
    "plt.plot(cumulative_strategy.index, cumulative_strategy.values, \n",
    "         label='Estratégia Lévy', linewidth=2, alpha=0.8)\n",
    "\n",
    "# Marcar períodos flat\n",
    "flat_periods = signals[signals == 0]\n",
    "for date in flat_periods.index:\n",
    "    plt.axvline(date, color='red', alpha=0.1, linewidth=1)\n",
    "\n",
    "plt.title('Comparação: Buy & Hold vs. Estratégia baseada em Quebras de Lévy')\n",
    "plt.ylabel('Retorno Cumulativo')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Métricas de performance\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "def calculate_metrics(returns):\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    annual_return = (1 + total_return) ** (252 / len(returns)) - 1\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "    max_dd = (returns.cumsum() - returns.cumsum().cummax()).min()\n",
    "    \n",
    "    return {\n",
    "        'Retorno Total': f\"{total_return:.2%}\",\n",
    "        'Retorno Anual': f\"{annual_return:.2%}\",\n",
    "        'Volatilidade Anual': f\"{annual_vol:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
    "        'Max Drawdown': f\"{max_dd:.2%}\"\n",
    "    }\n",
    "\n",
    "metrics_bh = calculate_metrics(buy_hold_returns)\n",
    "metrics_strategy = calculate_metrics(strategy_returns)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Buy & Hold': metrics_bh,\n",
    "    'Estratégia Lévy': metrics_strategy\n",
    "})\n",
    "\n",
    "print(\"\\nMétricas de Performance:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusões e Próximos Passos\n",
    "\n",
    "### Principais Descobertas:\n",
    "\n",
    "1. **Detecção de Quebras**: O método das seções de Lévy detectou com sucesso várias quebras estruturais que coincidem com eventos de mercado conhecidos.\n",
    "\n",
    "2. **Gaussianização**: As somas seccionais normalizadas apresentam distribuição mais próxima da normal, validando a teoria.\n",
    "\n",
    "3. **Features Robustas**: As features extraídas capturam características importantes da dinâmica de volatilidade.\n",
    "\n",
    "4. **Aplicação Prática**: Uma estratégia simples baseada nas quebras detectadas pode melhorar o perfil de risco-retorno.\n",
    "\n",
    "### Próximos Passos:\n",
    "\n",
    "1. **Integração com TSFresh**: Combinar features de Lévy com features do TSFresh para melhorar modelos de classificação.\n",
    "\n",
    "2. **Otimização de Parâmetros**: Desenvolver método sistemático para escolha ótima de τ e q.\n",
    "\n",
    "3. **Backtesting Robusto**: Testar estratégias em múltiplos ativos e períodos.\n",
    "\n",
    "4. **Machine Learning**: Usar as quebras detectadas como labels para treinar modelos preditivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados principais\n",
    "output_data = {\n",
    "    'features': features_df,\n",
    "    'breaks_summary': pd.DataFrame(breaks_info['breaks']),\n",
    "    'performance_metrics': metrics_df\n",
    "}\n",
    "\n",
    "# Criar diretório de saída se não existir\n",
    "output_dir = '../outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Salvar como Excel\n",
    "with pd.ExcelWriter(f'{output_dir}/levy_analysis_{datetime.now().strftime(\"%Y%m%d\")}.xlsx') as writer:\n",
    "    for sheet_name, df in output_data.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "        \n",
    "print(\"\\nResultados salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}